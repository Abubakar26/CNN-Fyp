{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnnp1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abubakar26/CNN-Fyp/blob/master/cnnp1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBnUUIvuxIUL",
        "colab_type": "code",
        "outputId": "e4047d28-595b-42bd-be46-7407a74a4795",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "DATA_PATH = \"/content/drive/My Drive/Colab Notebooks\"\n",
        "import pickle as pk\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras.layers import Dense,Dropout,Flatten\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "import pandas as pd\n",
        "batch_size = 128\n",
        "num_classes = 2\n",
        "epochs = 12\n",
        "import os\n",
        "path=\"/home/ab/Downloads/ChinaSet_AllFiles/\"\n",
        "#more,directory,files=next(os.walk(path))\n",
        "#print(directory)\n",
        "img_rows, img_cols = 90, 90\n",
        "pickle_in1=open(DATA_PATH+\"/Nig\",\"rb\")\n",
        "X=pk.load(pickle_in1)\n",
        "pickle_in2=open(DATA_PATH+\"/Nig2\",\"rb\")\n",
        "Y=pk.load(pickle_in2)\n",
        "print(X)\n",
        "print(Y)\n",
        "X,Y=shuffle(X,Y)\n",
        "x_train,x_test,y_train,y_test = tts(X,Y,train_size=0.8)\n",
        "# convert class vectors to binary class matrices\n",
        "x_train=np.array(x_train)\n",
        "y_train=np.array(y_train)\n",
        "x_test=np.array(x_test)\n",
        "y_test=np.array(y_test)\n",
        "\n",
        "print(\"Xtrain\",x_train.shape)\n",
        "print(\"Ytrain\",y_train.shape)\n",
        "print(\"Ytest\",y_test.shape)\n",
        "print(\"Xtest\",x_test.shape)\n",
        "\n",
        "#Y_train = keras.utils.to_categorical(y_train)\n",
        "X_test = keras.utils.to_categorical(x_test)\n",
        "X_train=keras.utils.to_categorical(x_train)\n",
        "#print(Y_train)\n",
        "#print(y_train)\n",
        "#print(x_test)\n",
        "#print(y_test)\n",
        "#rint(Y_test.shape)\n",
        "print(X_train.shape)\n",
        "#print(Y_test[0])\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='sigmoid',\n",
        "                 input_shape=(90,90,256)))\n",
        "model.add(Conv2D(64, (3, 3), activation='sigmoid',input_shape=(90,90,256)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='relu'))\n",
        "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "model.fit(X_train,y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_split=0.1,shuffle=True)\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score)\n",
        "print('Test accuracy:', score)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[[[[ 16]\n",
            "   [ 13]\n",
            "   [ 11]\n",
            "   ...\n",
            "   [  8]\n",
            "   [  2]\n",
            "   [  3]]\n",
            "\n",
            "  [[ 10]\n",
            "   [  9]\n",
            "   [  7]\n",
            "   ...\n",
            "   [  5]\n",
            "   [  8]\n",
            "   [  8]]\n",
            "\n",
            "  [[ 10]\n",
            "   [  7]\n",
            "   [  5]\n",
            "   ...\n",
            "   [  3]\n",
            "   [  3]\n",
            "   [  7]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 40]\n",
            "   [ 37]\n",
            "   [ 95]\n",
            "   ...\n",
            "   [ 41]\n",
            "   [ 10]\n",
            "   [  0]]\n",
            "\n",
            "  [[ 36]\n",
            "   [ 34]\n",
            "   [ 47]\n",
            "   ...\n",
            "   [  2]\n",
            "   [ 10]\n",
            "   [  0]]\n",
            "\n",
            "  [[ 91]\n",
            "   [ 56]\n",
            "   [ 24]\n",
            "   ...\n",
            "   [  6]\n",
            "   [  9]\n",
            "   [  0]]]\n",
            "\n",
            "\n",
            " [[[ 54]\n",
            "   [ 46]\n",
            "   [ 47]\n",
            "   ...\n",
            "   [ 73]\n",
            "   [ 78]\n",
            "   [ 91]]\n",
            "\n",
            "  [[ 50]\n",
            "   [ 40]\n",
            "   [ 37]\n",
            "   ...\n",
            "   [ 66]\n",
            "   [ 71]\n",
            "   [ 83]]\n",
            "\n",
            "  [[ 42]\n",
            "   [ 35]\n",
            "   [ 30]\n",
            "   ...\n",
            "   [ 66]\n",
            "   [ 69]\n",
            "   [ 79]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[124]\n",
            "   [131]\n",
            "   [136]\n",
            "   ...\n",
            "   [ 55]\n",
            "   [ 56]\n",
            "   [ 71]]\n",
            "\n",
            "  [[164]\n",
            "   [164]\n",
            "   [170]\n",
            "   ...\n",
            "   [ 55]\n",
            "   [ 57]\n",
            "   [ 69]]\n",
            "\n",
            "  [[  0]\n",
            "   [  0]\n",
            "   [  0]\n",
            "   ...\n",
            "   [131]\n",
            "   [131]\n",
            "   [136]]]\n",
            "\n",
            "\n",
            " [[[ 16]\n",
            "   [ 16]\n",
            "   [ 16]\n",
            "   ...\n",
            "   [ 20]\n",
            "   [ 21]\n",
            "   [ 20]]\n",
            "\n",
            "  [[ 15]\n",
            "   [ 16]\n",
            "   [ 15]\n",
            "   ...\n",
            "   [ 18]\n",
            "   [ 21]\n",
            "   [ 20]]\n",
            "\n",
            "  [[ 15]\n",
            "   [ 15]\n",
            "   [ 15]\n",
            "   ...\n",
            "   [ 20]\n",
            "   [ 23]\n",
            "   [ 19]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 17]\n",
            "   [ 17]\n",
            "   [ 18]\n",
            "   ...\n",
            "   [ 18]\n",
            "   [ 20]\n",
            "   [ 19]]\n",
            "\n",
            "  [[ 18]\n",
            "   [ 18]\n",
            "   [ 18]\n",
            "   ...\n",
            "   [ 19]\n",
            "   [ 18]\n",
            "   [ 18]]\n",
            "\n",
            "  [[ 16]\n",
            "   [ 18]\n",
            "   [ 17]\n",
            "   ...\n",
            "   [ 19]\n",
            "   [ 20]\n",
            "   [  0]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 19]\n",
            "   [ 19]\n",
            "   [ 18]\n",
            "   ...\n",
            "   [ 17]\n",
            "   [ 17]\n",
            "   [ 18]]\n",
            "\n",
            "  [[  8]\n",
            "   [  9]\n",
            "   [  8]\n",
            "   ...\n",
            "   [  8]\n",
            "   [  9]\n",
            "   [  9]]\n",
            "\n",
            "  [[  8]\n",
            "   [  7]\n",
            "   [  7]\n",
            "   ...\n",
            "   [  9]\n",
            "   [ 11]\n",
            "   [ 10]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 14]\n",
            "   [ 12]\n",
            "   [ 12]\n",
            "   ...\n",
            "   [ 13]\n",
            "   [ 15]\n",
            "   [ 14]]\n",
            "\n",
            "  [[ 12]\n",
            "   [ 13]\n",
            "   [ 14]\n",
            "   ...\n",
            "   [ 15]\n",
            "   [ 13]\n",
            "   [ 15]]\n",
            "\n",
            "  [[ 13]\n",
            "   [ 11]\n",
            "   [ 11]\n",
            "   ...\n",
            "   [ 15]\n",
            "   [ 14]\n",
            "   [  0]]]\n",
            "\n",
            "\n",
            " [[[ 13]\n",
            "   [ 15]\n",
            "   [ 15]\n",
            "   ...\n",
            "   [ 17]\n",
            "   [ 16]\n",
            "   [ 17]]\n",
            "\n",
            "  [[ 14]\n",
            "   [ 14]\n",
            "   [ 16]\n",
            "   ...\n",
            "   [ 17]\n",
            "   [ 17]\n",
            "   [ 19]]\n",
            "\n",
            "  [[ 17]\n",
            "   [ 15]\n",
            "   [ 16]\n",
            "   ...\n",
            "   [ 18]\n",
            "   [ 17]\n",
            "   [ 19]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 20]\n",
            "   [ 20]\n",
            "   [ 19]\n",
            "   ...\n",
            "   [ 21]\n",
            "   [ 23]\n",
            "   [ 27]]\n",
            "\n",
            "  [[ 19]\n",
            "   [ 20]\n",
            "   [ 18]\n",
            "   ...\n",
            "   [ 26]\n",
            "   [ 24]\n",
            "   [ 24]]\n",
            "\n",
            "  [[ 20]\n",
            "   [ 19]\n",
            "   [ 19]\n",
            "   ...\n",
            "   [ 26]\n",
            "   [ 24]\n",
            "   [  0]]]\n",
            "\n",
            "\n",
            " [[[ 34]\n",
            "   [ 28]\n",
            "   [ 30]\n",
            "   ...\n",
            "   [ 53]\n",
            "   [ 60]\n",
            "   [ 62]]\n",
            "\n",
            "  [[ 31]\n",
            "   [ 30]\n",
            "   [ 30]\n",
            "   ...\n",
            "   [ 55]\n",
            "   [ 64]\n",
            "   [ 63]]\n",
            "\n",
            "  [[ 30]\n",
            "   [ 28]\n",
            "   [ 25]\n",
            "   ...\n",
            "   [ 57]\n",
            "   [ 55]\n",
            "   [ 59]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 28]\n",
            "   [ 26]\n",
            "   [ 27]\n",
            "   ...\n",
            "   [ 42]\n",
            "   [ 38]\n",
            "   [ 44]]\n",
            "\n",
            "  [[ 76]\n",
            "   [ 73]\n",
            "   [ 71]\n",
            "   ...\n",
            "   [ 50]\n",
            "   [ 53]\n",
            "   [ 59]]\n",
            "\n",
            "  [[  0]\n",
            "   [  0]\n",
            "   [  0]\n",
            "   ...\n",
            "   [126]\n",
            "   [120]\n",
            "   [126]]]]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "Xtrain (640, 90, 90, 1)\n",
            "Ytrain (640,)\n",
            "Ytest (160,)\n",
            "Xtest (160, 90, 90, 1)\n",
            "(640, 90, 90, 256)\n",
            "Train on 576 samples, validate on 64 samples\n",
            "Epoch 1/12\n",
            "576/576 [==============================] - 7s 12ms/step - loss: 3.4794 - acc: 0.4826 - val_loss: 0.6931 - val_acc: 0.5312\n",
            "Epoch 2/12\n",
            "576/576 [==============================] - 3s 6ms/step - loss: 0.9026 - acc: 0.4948 - val_loss: 0.6931 - val_acc: 0.5312\n",
            "Epoch 3/12\n",
            "576/576 [==============================] - 3s 6ms/step - loss: 0.8442 - acc: 0.4948 - val_loss: 0.6931 - val_acc: 0.5312\n",
            "Epoch 4/12\n",
            "576/576 [==============================] - 3s 6ms/step - loss: 0.9769 - acc: 0.4948 - val_loss: 0.6931 - val_acc: 0.5312\n",
            "Epoch 5/12\n",
            "576/576 [==============================] - 3s 6ms/step - loss: 0.8442 - acc: 0.4948 - val_loss: 0.6931 - val_acc: 0.5312\n",
            "Epoch 6/12\n",
            "576/576 [==============================] - 3s 6ms/step - loss: 0.8210 - acc: 0.4948 - val_loss: 0.6931 - val_acc: 0.5312\n",
            "Epoch 7/12\n",
            "576/576 [==============================] - 3s 6ms/step - loss: 0.8722 - acc: 0.4948 - val_loss: 0.6931 - val_acc: 0.5312\n",
            "Epoch 8/12\n",
            "576/576 [==============================] - 3s 6ms/step - loss: 0.8246 - acc: 0.4948 - val_loss: 0.6931 - val_acc: 0.5312\n",
            "Epoch 9/12\n",
            "576/576 [==============================] - 3s 6ms/step - loss: 1.0073 - acc: 0.4948 - val_loss: 0.6931 - val_acc: 0.5312\n",
            "Epoch 10/12\n",
            "576/576 [==============================] - 3s 6ms/step - loss: 0.9977 - acc: 0.4948 - val_loss: 0.6931 - val_acc: 0.5312\n",
            "Epoch 11/12\n",
            "576/576 [==============================] - 3s 6ms/step - loss: 0.6931 - acc: 0.4948 - val_loss: 0.6931 - val_acc: 0.5312\n",
            "Epoch 12/12\n",
            "576/576 [==============================] - 3s 6ms/step - loss: 0.6931 - acc: 0.4948 - val_loss: 0.6931 - val_acc: 0.5312\n",
            "Test loss: [0.6931471824645996, 0.54375]\n",
            "Test accuracy: [0.6931471824645996, 0.54375]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}